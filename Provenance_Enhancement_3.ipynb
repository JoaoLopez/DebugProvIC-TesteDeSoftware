{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following cells presents an execution tree enhanced with provenance.\n",
    "### In this view, the wrong Evaluation is asked, and the provenance DAG is built based on the slice of the wrong evaluation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sqlite3\n",
    "\n",
    "from graphviz import Graph\n",
    "\n",
    "from debugprov.validity import Validity\n",
    "from debugprov.node import Node\n",
    "from debugprov.execution_tree import ExecutionTree\n",
    "from debugprov.execution_tree_creator import ExecTreeCreator\n",
    "from debugprov.top_down import TopDown\n",
    "from debugprov.heaviest_first import HeaviestFirst\n",
    "from debugprov.visualization import Visualization\n",
    "from debugprov.provenance_enhancement import ProvenanceEnhancement \n",
    "from debugprov.single_stepping import SingleStepping\n",
    "from debugprov.divide_and_query import DivideAndQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomVisualization(Visualization):\n",
    "\n",
    "    # CUSTOM ATTRIBUTES\n",
    "    PROVENANCE_NODE_COLOR = 'lightblue'\n",
    "    \n",
    "    def generate_exec_tree(self, graph_name = 'exec_tree'):\n",
    "        file_name = \"{}.gv\".format(graph_name)\n",
    "        self.graph = Graph(graph_name, filename=file_name)\n",
    "        self.graph.attr('node', shape='box')\n",
    "        self.graph.attr('graph', ordering='out')\n",
    "        root_node = self.exec_tree.root_node\n",
    "        self.graph.node(str(root_node.ev_id), root_node.get_name(), fillcolor=self.INVALID_COLOR, style='filled') # root node\n",
    "        self.navigate(root_node)\n",
    "        eval_node = self.exec_tree.node_under_evaluation\n",
    "        if eval_node is not None:\n",
    "            self.graph.node(str(eval_node.ev_id), str(eval_node.get_name()), fillcolor=self.NODE_IN_EVALUATION, style='filled')\n",
    "        buggy_node = self.exec_tree.buggy_node\n",
    "        if buggy_node is not None:\n",
    "            self.graph.node(str(buggy_node.ev_id), str(buggy_node.get_name()), fillcolor=self.BUGGY_NODE_COLOR, style='filled')\n",
    "        if self.exec_tree.dependencies is not None:\n",
    "            count = 0\n",
    "            for d in self.exec_tree.dependencies: # this loop draws the provenance links between nodes\n",
    "                count += 1\n",
    "                print(\" # {} \".format(count),end='')\n",
    "                self.graph.edge(str(d.dependent.ev_id), str(d.influencer.ev_id), None, color=self.PROVENANCE_EDGE_COLOR, dir='forward')\n",
    "                ## BEGIN customization\n",
    "                self.graph.node(str(d.dependent.ev_id), None, fillcolor=self.PROVENANCE_NODE_COLOR, style='filled')\n",
    "                self.graph.node(str(d.influencer.ev_id), None, fillcolor=self.PROVENANCE_NODE_COLOR, style='filled')\n",
    "                ## END customization\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOW2_SQLITE_PATH = 'C:/Users/linha/Desktop/ws/py-scripts-examples/paper_example/.noworkflow/db.sqlite'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CURSOR = sqlite3.connect(NOW2_SQLITE_PATH).cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "creator = ExecTreeCreator(CURSOR)\n",
    "exec_tree = creator.create_exec_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prov = ProvenanceEnhancement(exec_tree, CURSOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which evaluation id is not correct? 101\n"
     ]
    }
   ],
   "source": [
    "wrong_data = prov.ask_wrong_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<debugprov.evaluation.Evaluation at 0x1ad1e6eae80>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prov.dependencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOUND\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'print(\"maximum: {}\".format(maximum))'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for e in prov.dependencies:\n",
    "    if e.ev_id == wrong_data.ev_id:\n",
    "        wd = e\n",
    "        print(\"FOUND\")\n",
    "wd.code_component_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "<debugprov.evaluation.Evaluation object at 0x000001AD1E6F2A90>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-2b61c199e5d9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprov\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menhance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrong_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mev_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Desktop\\ws\\DebugProv\\debugprov\\provenance_enhancement.py\u001b[0m in \u001b[0;36menhance\u001b[1;34m(self, wrong_node_id)\u001b[0m\n\u001b[0;32m     55\u001b[0m                 \u001b[0msearch_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidity\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mValidity\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUNKNOWN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m             \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvisited\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdependencies\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfinal_dependencies\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDependencyRel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'visited'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: <debugprov.evaluation.Evaluation object at 0x000001AD1E6F2A90>"
     ]
    }
   ],
   "source": [
    "prov.enhance(wrong_data.ev_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(exec_tree.dependencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis = Visualization(prov.exec_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.view_exec_tree('exec_tree_p3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a(10)\n"
     ]
    }
   ],
   "source": [
    "for e in exec_tree.dependencies[wd]:\n",
    "    print(e.code_component_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wd.ev_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# num \n",
      "# 10 \n",
      "# num \n",
      "# x \n",
      "# x \n",
      "# j \n",
      "# j \n",
      "# j-3 \n",
      "# 3 \n",
      "# c(x) \n",
      "# c(x)*4 \n",
      "===- c(x)\n",
      "# 4 \n",
      "# b(num) \n",
      "===- c(x)\n",
      "# num \n",
      "===- b(num)\n",
      "# num \n",
      "===- b(num)\n",
      "# num*2 \n",
      "===- b(num)\n",
      "# 2 \n",
      "# a(10) \n",
      "===- b(num)\n",
      "# print(a(10)) \n",
      "===- a(10)\n"
     ]
    }
   ],
   "source": [
    "reach = prov.dependencies\n",
    "for item in reach:\n",
    "    k = item\n",
    "    v = reach[item] \n",
    "    print(\"# {} \".format(k.code_component_name))\n",
    "    for elem in v:\n",
    "        print(\"===- {}\".format(elem.code_component_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num\n",
      "    set()\n",
      "10\n",
      "    set()\n",
      "num\n",
      "    set()\n",
      "x\n",
      "    set()\n",
      "x\n",
      "    set()\n",
      "j\n",
      "    set()\n",
      "j\n",
      "    set()\n",
      "j-3\n",
      "    set()\n",
      "3\n",
      "    set()\n",
      "c(x)\n",
      "    set()\n",
      "c(x)*4\n",
      "    {<debugprov.evaluation.Evaluation object at 0x000002045DE54908>}\n",
      "4\n",
      "    set()\n",
      "b(num)\n",
      "    {<debugprov.evaluation.Evaluation object at 0x000002045DE54908>}\n",
      "num\n",
      "    {<debugprov.evaluation.Evaluation object at 0x000002045DE54F28>}\n",
      "num\n",
      "    {<debugprov.evaluation.Evaluation object at 0x000002045DE54F28>}\n",
      "num*2\n",
      "    {<debugprov.evaluation.Evaluation object at 0x000002045DE54F28>}\n",
      "2\n",
      "    set()\n",
      "a(10)\n",
      "    {<debugprov.evaluation.Evaluation object at 0x000002045DE54F28>}\n",
      "print(a(10))\n",
      "    {<debugprov.evaluation.Evaluation object at 0x000002045DE4E7F0>}\n"
     ]
    }
   ],
   "source": [
    "len(reach)\n",
    "for item in reach:\n",
    "    print(item.code_component_name)\n",
    "    print(\"    {}\".format(reach[item]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
